{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY='jingfeng'\n",
      "env: DEEPEVAL_RESULTS_FOLDER=mme_results\n"
     ]
    }
   ],
   "source": [
    "from models.BaseModelTest import ModelTestConfig, BaseModelTest\n",
    "from models.MME_TestModel import MME_TestModel\n",
    "from datasets import load_dataset, get_dataset_config_names\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "%env OPENAI_API_KEY='jingfeng'\n",
    "%env DEEPEVAL_RESULTS_FOLDER=mme_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating goldens: 100it [22:10, 13.31s/it]\n",
      "  3%|â–Ž         | 1/30 [22:15<10:45:43, 1335.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goldens saved to MMMU_Goldens/Accounting.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427f5d0719f34ac491de212b86153bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/22.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa0fd222f3e43c1a15e88291935d373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/119M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ad70c3250f42d39bc9573f388e3e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00002.parquet:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf8276d50d74bf8b23f4d0a62cc6896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00001-of-00002.parquet:   0%|          | 0.00/489M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5b4ed08ea144e78a9df0b245b083f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cee367a0cf4da2a6e640824ee85b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afc6c1eec6649c88f8fe65037a6ca19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "from models.MMMU_TestModel import MMMU_Test_Model\n",
    "mmmu_goldens = Path('MMMU_Goldens')\n",
    "MMMU_URL = 'MMMU/MMMU'\n",
    "EVAL_MMMU = True\n",
    "if EVAL_MMMU: \n",
    "    mmmu_configs = get_dataset_config_names(MMMU_URL)\n",
    "    mmmu_results = {}\n",
    "    for config in tqdm(mmmu_configs):\n",
    "        mmmu_ds = load_dataset(MMMU_URL, config)['test']\n",
    "        mmmu_df = pd.DataFrame(mmmu_ds).iloc[:100, :]\n",
    "        mmmu_model_config = ModelTestConfig(model_name='openai/internvl2_5')\n",
    "        mmmu_model = MMMU_Test_Model(mmmu_model_config)\n",
    "        mmmu_model.make_data(mmmu_df)\n",
    "        mmmu_model.make_goldens()\n",
    "        mmmu_model.save_goldens(mmmu_goldens / (config + '.pkl'))\n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EVAL_MME = False\n",
    "if EVAL_MME:\n",
    "    ds = load_dataset(\"darkyarding/MME\")['test']\n",
    "    df = pd.DataFrame(ds)\n",
    "    mme_config = ModelTestConfig(model_name='openai/internvl2_5')\n",
    "    mme_model = MME_TestModel(mme_config)\n",
    "    mme_model.make_data(df)\n",
    "    mme_model.make_goldens()\n",
    "    mme_model.set_eval()\n",
    "    mme_model.evaluate_llm()\n",
    "    success_num, total_num, ratio = mme_model.get_success_rate()\n",
    "    print(\"Success_num: \", success_num)\n",
    "    print(\"total_num: \", total_num)\n",
    "    print(\"ratio: \", ratio)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
